{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to `sns_modeling` tool\n",
    "\n",
    "The separation network synthesis (sns) tool provides an initial design for distillation separation systems using thermally coupled distillation columns. The intent of the tool is to determine cost optimal separation network structure for process synthesis and intensification applications. This notebook provides an overview of how to install and use the package to build and solve separation network synthesis problems.\n",
    "\n",
    "The main goals of the tool are to aid a designer in determining:\n",
    "\n",
    "1. Selection of component splits in a separation network\n",
    "2. Process toplogy with and emphasis on heat exchanger\n",
    "3. Initial sizing and costing of unit operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "\n",
    "1. [Package Setup and Installation](##1-package-setup-and-installation)\n",
    "2. [Package Structure](##2-package-structure)\n",
    "3. [Problem Setup and Data Loading](##3.problem-setup-and-data-loading)\n",
    "4. [Problem Scaling and Transformation](##4.problem-scaling-and-transformation)\n",
    "5. [Problem Solution](##5.problem-solution)\n",
    "6. [Solution Output and Interpretation](##6.solution-output-and-interpretation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Package Setup and Installation\n",
    "\n",
    "Download or clone the package from the Github repo [sns_modeling](https://github.com/pfauk/sns_modeling). In a terminal, navigate to the directory location and install the package dependencies by running: \n",
    "\n",
    "```\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "**Important**: this package requires an installed version of Gurobi to solve the MIQCP model. It is possible to pip install Gurobi from the Python Package Index (PyPI). However, the free version comes with a trial license that will only be able to solve models of a smaller size (2,000 variables or constraints).\n",
    "\n",
    "After installing dependencies, navigate to the directory of the package and run:\n",
    "\n",
    "```\n",
    "pip install -e . \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Package Structure\n",
    "\n",
    "The package has several main components that contribute to the overall functionality of the design tool. The main components are:\n",
    "\n",
    "1. Model generation\n",
    "2. Superstrucutre generation\n",
    "3. Data directory\n",
    "4. Utilities\n",
    "5. Documentation\n",
    "\n",
    "**1. Model generation**\n",
    "\n",
    "The Pyomo Concrete Model object is generated through a function call to the 'build_model' function in `src\\thermal_coupled\\therm_dist.py`. All of the mathematical modeling components are defined and documented in this script. This function is the core functionality of the package.\n",
    "\n",
    "**2. Superstrucutre generation**\n",
    "\n",
    "An important aspect of process synthesis modeling is defining a process superstrucutre. This package includes functionality to automatically generate a network superstructure and pass it to the build model function. The `src\\superstructure` directory contains the functionality to build the state task network (stn) for the superstructure of the problem.\n",
    "\n",
    "**3. Data directory**\n",
    "\n",
    "Data for this problem should be structured in the format of the provided exampled excel spreadsheets in the `src\\data`. Users do not have to place data files in that directory, but it is the default location for the utility functions to pull data from. \n",
    "\n",
    "**4. Utilities**\n",
    "\n",
    "The `utils.py` script contains functionality for loading data from excel spreadsheets into objects that can be passed to the `build_model function`. There are utility functions for printing and saving models and the resulting solutions.\n",
    "\n",
    "**5. Documentation**\n",
    "\n",
    "The `docs` directory contains files that give a detailed explanation of the mathematical model, empirical correlations that were used, and superstructure defintion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Problem Setup and Data Loading\n",
    "\n",
    "Here we will show how to use the modeling tool's core functionality to build and solve a process synthesis problem. The general problem that we want to solve is: \n",
    "\n",
    "*Given an N component zeotropic mixture, determine the cost optimal separation sequence, column design, and heat integration to separate the mixture into N components*.\n",
    "\n",
    "This can be generally visualized as separating some mixture of components {A, B, C, D} into streams of relatively high purity.\n",
    "\n",
    "\n",
    "<img src=\"images/problem_statement.png\" alt=\"Problem Statement\" width=\"550\" height=\"250\">\n",
    "\n",
    "*Representation of the conceptual problem of separating a 4 component mixture into 4 high purity product streams*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow for this design problem can be outlined as:\n",
    "\n",
    "1. Define and construct a process superstructure\n",
    "2. Define all relevant species and system data\n",
    "3. Build the generalized disjunctive program (GDP)\n",
    "4. Transform the GDP into a mixed integer quadratically constrained program (MIQCP)\n",
    "5. Solve the mathematical program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 a. Process Superstructure\n",
    "\n",
    "We first need to represent the overall superstructure of a distillation process. The superstructure represents the solution space to the problem, so the representation has to be sufficiently detailed to provide a meaningful solution representation. The \n",
    "\n",
    "For a single distillation column, we specify light key and heavy components that we want to separate out in high purity in the distillate and bottoms respectively. This is referred to as the split of the components in a mixture. There are two options for how to specify the key components. For a given mixture, that is ordered by decreasing relative volatility, \n",
    "\n",
    "ABC: {A/BC, AB/C}\n",
    "\n",
    "Splits between non-consecutive key components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'thermal_coupled.therm_dist_scaled_test'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msuperstructure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stn\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msuperstructure\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstn_nonconsecutive\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m stn_nonconsecutive\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mthermal_coupled\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtherm_dist_scaled_test\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m build_model\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'thermal_coupled.therm_dist_scaled_test'"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "import logging\n",
    "import os\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.util.infeasible import log_infeasible_constraints, find_infeasible_constraints\n",
    "from pyomo.util.model_size import build_model_size_report\n",
    "from idaes.core.util.model_statistics import report_statistics\n",
    "from utils import (\n",
    "    Data,\n",
    "    get_model_type,\n",
    "    pprint_network,\n",
    "    pprint_tasks,\n",
    "    save_model_to_file,\n",
    "    save_solution_to_file,\n",
    "    get_model_type,\n",
    "    print_constraint_type)\n",
    "from superstructure.stn import stn\n",
    "from superstructure.stn_nonconsecutive import stn_nonconsecutive\n",
    "from thermal_coupled.therm_dist_scaled_test import build_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# specify number of components and data file name\n",
    "n = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 b. Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Build Optimization Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Species parameters**\n",
    "\n",
    "![](./images/species_params.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sheet contains parameters for each chemical species in the system. Species index should just be upper case capital letters: A, B, C, D. Species should be ordered by decreasing relative volatility, with A as the most volatile and the last species as the least volatile.\n",
    "\n",
    "Inlet fractions are mole fractions. Enure they sum to 1.\n",
    "\n",
    "Relative volatilities can be determine from ASPEN properties for binary mixtures relative to the least volatile species in the system. The relative volatility ($\\alpha_i$) should be found in ASPEN for the temperature and pressure specified in the system sheet. The system is modeled so that the feeds are liquids at bubble point. The liquid density of the species at the system temperature and pressure is used to do empirical correlations for equipment sizing.\n",
    "\n",
    "The recovery ($x_i$) for each component is the fraction of the molar flow in the outlet of that species stream, relative to the total inlet to the system. Note that a product recovery constraint is different than a product purity constraint. Setting the recoveries too high (such as setting all the recoveries to values of 1) may lead to an infeasible problem, as such a separation could require columns with an infinite number of stages. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Problem Scaling and Transformation\n",
    "\n",
    "Here we will show an example of building and solving a problem with a system feed with 4 components and splits between consecutive key components. Not all of the below import statements are required. Many are used to save and inspect the model after completion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements \n",
    "\n",
    "import logging\n",
    "import pyomo.environ as pyo\n",
    "from pyomo.util.infeasible import log_infeasible_constraints, find_infeasible_constraints\n",
    "from pyomo.util.model_size import build_model_size_report\n",
    "from utils import (\n",
    "    Data,\n",
    "    get_model_type,\n",
    "    pprint_network,\n",
    "    pprint_tasks,\n",
    "    save_model_to_file,\n",
    "    save_solution_to_file,\n",
    "    get_model_type,\n",
    "    print_constraint_type)\n",
    "from superstructure.stn import stn\n",
    "from superstructure.stn_nonconsecutive import stn_nonconsecutive\n",
    "from thermal_coupled.therm_dist import build_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you will import data from the data file (excel) located in the `src\\data\\` directory. The `Data` class from the `utils.py` script will be used to hold all the problem data and pass it as an arguement to the `build_model` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Inlet data\n",
      "================================================================\n",
      "   F0 [kmol/hr]  Pressure [bar]  Temp [C]  Cost cooling [$/kJ]  \\\n",
      "0           300               1        85               0.0015   \n",
      "\n",
      "   Cost heating [$/kJ]  \n",
      "0                0.005  \n",
      "\n",
      "Mixture species data\n",
      "================================================================\n",
      "        Species index  Inlet Mole Frac  Relative Volatility  \\\n",
      "0       Benzene     A              0.1                8.015   \n",
      "1       Toluene     B              0.4                3.084   \n",
      "2  Ethylbenzene     C              0.3                1.344   \n",
      "3       Styrene     D              0.2                1.000   \n",
      "\n",
      "   Liquid Density [kg/m^3]  Molecular Weight  \\\n",
      "0                      876                78   \n",
      "1                      867                92   \n",
      "2                      866               106   \n",
      "3                      906               104   \n",
      "\n",
      "   Enthalpy of Vaporization [kJ/mol]  Recovery  \n",
      "0                              30.77      0.95  \n",
      "1                              33.19      0.95  \n",
      "2                              35.58      0.95  \n",
      "3                              36.83      0.95  \n"
     ]
    }
   ],
   "source": [
    "# specify number of components and data file name\n",
    "n = 4\n",
    "data_file_name = '4_comp_hydrocarbon_1.xlsx'\n",
    "\n",
    "# import problem data for system and relevant species to data object\n",
    "mixture_data = Data(data_file_name)\n",
    "\n",
    "# can inspect the Data object\n",
    "print()\n",
    "print('Inlet data')\n",
    "print('================================================================')\n",
    "print(mixture_data.system_df)\n",
    "\n",
    "print()\n",
    "print('Mixture species data')\n",
    "print('================================================================')\n",
    "print(mixture_data.species_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, build the problem superstucture by specifying the number of components. The `superstructure\\stn.py` script contains functionality for state task network with splits between both consecutive and non-consecutive components. The class `stn` builds a tree and index sets for splits between consecutive key components. You could also choose to use `stn_nonconsecutive` imported from `superstructure\\stn_nonconsecutive.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build state-task network superstrucutre and associated index sets\n",
    "network_superstructure = stn(n)\n",
    "network_superstructure.generate_tree()\n",
    "network_superstructure.generate_index_sets()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![stn consecutive splits](./images/consecutive_split_stn.png)\n",
    "\n",
    "*A state task network for a 4 component mixture with splits between **consecutive** key components*\n",
    "\n",
    "![stn nonconsecutive splits](./images/nonconsecutive_split_stn.png)\n",
    "\n",
    "*A state task network for a 4 component mixture with splits between **nonconsecutive** key components*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State(ABCD)\n",
      "  Task(A/BCD)\n",
      "    State(A, final=True)\n",
      "    State(BCD)\n",
      "      Task(B/CD)\n",
      "        State(B, final=True)\n",
      "        State(CD)\n",
      "          Task(C/D)\n",
      "            State(C, final=True)\n",
      "            State(D, final=True)\n",
      "      Task(BC/D)\n",
      "        State(BC)\n",
      "          Task(B/C)\n",
      "            State(B, final=True)\n",
      "            State(C, final=True)\n",
      "        State(D, final=True)\n",
      "  Task(AB/CD)\n",
      "    State(AB)\n",
      "      Task(A/B)\n",
      "        State(A, final=True)\n",
      "        State(B, final=True)\n",
      "    State(CD)\n",
      "      Task(C/D)\n",
      "        State(C, final=True)\n",
      "        State(D, final=True)\n",
      "  Task(ABC/D)\n",
      "    State(ABC)\n",
      "      Task(A/BC)\n",
      "        State(A, final=True)\n",
      "        State(BC)\n",
      "          Task(B/C)\n",
      "            State(B, final=True)\n",
      "            State(C, final=True)\n",
      "      Task(AB/C)\n",
      "        State(AB)\n",
      "          Task(A/B)\n",
      "            State(A, final=True)\n",
      "            State(B, final=True)\n",
      "        State(C, final=True)\n",
      "    State(D, final=True)\n"
     ]
    }
   ],
   "source": [
    "# can visualize the superstructure if desired\n",
    "network_superstructure.print_tree()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now build the Pyomo model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pyomo.core.base.PyomoModel.ConcreteModel'>\n"
     ]
    }
   ],
   "source": [
    "model = build_model(network_superstructure, mixture_data)\n",
    "\n",
    "# returns a Pyomo Concrete Model object\n",
    "print(type(model))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It can sometimes be useful to inspect the model object throughout the workflow. The model that is constructed by the `build_model` function is a generalized disjunctive program (GDP). The `get_model_type` from `utils.py` allows you to see what type of mathematical model the Pyomo model object contains. Furthermore, the `save_model_to_file` function can be used to create a text file to inspect the entire model object in a pretty printed format. Saving the model for inspection is best done prior to transforming of the GDP model. By default, the pretty printed Pyomo model is saved to `thermal_coupled\\saved_models`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the pyomo model to a file\n",
    "save_model_to_file(model, '4_comp_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the model type prior to transformation\n",
    "print(f'Model type before transformation: {get_model_type(model)}')\n",
    "\n",
    "# use of Pyomo.GDP to apply Big-M transformation\n",
    "pyo.TransformationFactory('core.logical_to_linear').apply_to(model)\n",
    "\n",
    "mbigm = pyo.TransformationFactory('gdp.bigm')\n",
    "mbigm.apply_to(model)\n",
    "\n",
    "print(f'Model type after transformation: {get_model_type(model)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Problem Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After applying the Big-M transformation using Pyomo.GDP's TransformationFactory, the Pyomo model is a non-convex mixed-integer quadratically constrained program (MIQCP). We can use Gurobi to solve the model. Gurobi has a number of parameters that can be passed to the solver. A [full list of solver parameters](https://www.gurobi.com/documentation/current/refman/parameters.html) can be founds on the Gurobi website. For now we recommend setting the NumericFocus and nonConvex parameters to values of 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pyomo solver factory\n",
    "solver = pyo.SolverFactory('gurobi')\n",
    "\n",
    "# Gurobi solver options\n",
    "solver.options = {'NumericFocus': 2,\n",
    "                  'nonConvex': 2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now send the Pyomo model to the solver. The logging setup helps to troubleshoot any infeasible constraints that might exist in the model. It is not uncommon to have some infeasible log statements as a result of some of the transformation variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pyomo.util.infeasible:CONSTR _pyomo_gdp_bigm_reformulation.relaxedDisjuncts[0].transformedConstraints['intermediate_var_con[C,r1]_32',(C,r1),lb]: 1.0 </= 0.9999986519279662\n",
      "INFO:pyomo.util.infeasible:CONSTR _pyomo_gdp_bigm_reformulation.relaxedDisjuncts[0].transformedConstraints['intermediate_var_con[D,r1]_34',(D,r1),lb]: 1.0 </= 0.9999987956263393\n",
      "INFO:pyomo.util.infeasible:CONSTR _pyomo_gdp_bigm_reformulation.relaxedDisjuncts[6].transformedConstraints['intermediate_var_con[D,r1]_40',(D,r1),lb]: 1.0 </= 0.9999983298108829\n",
      "INFO:pyomo.util.infeasible:CONSTR _pyomo_gdp_bigm_reformulation.relaxedDisjuncts[10].transformedConstraints['intermediate_var_con[C,r1]_40',(C,r1),lb]: 1.0 </= 0.9999985998324995\n",
      "INFO:pyomo.util.infeasible:CONSTR _pyomo_gdp_bigm_reformulation.relaxedDisjuncts[10].transformedConstraints['intermediate_var_con[C,r3]_44',(C,r3),lb]: 1.0 </= 0.9999985248596212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<generator object find_infeasible_constraints at 0x00000238E7BC1A40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = solver.solve(model, tee=True)\n",
    "\n",
    "# Log infeasible constraints if any\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "log_infeasible_constraints(model)\n",
    "find_infeasible_constraints(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To see the output of the solution, just use the `print_network` function from the package utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pprint_network(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can save the pretty printed solution output to a text file with the used of `save_solution_to_file`. The `thermal_coupled\\results` directory is the default save location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_solution_to_file(model, '4_comp_solution_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "def_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
